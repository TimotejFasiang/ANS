{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e83decf-71f9-48e5-bffc-17d548c2e0de",
   "metadata": {},
   "source": [
    "# Klasifikace obrázků CIFAR-10 pomocí konvoluční sítě"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c076e-79f8-48ae-8088-461d9c224911",
   "metadata": {},
   "source": [
    "Úkolem cvičení je natrénovat konvoluční síť pro klasifikaci na datasetu CIFAR-10 s alespoň 75% úpěšností na validační sadě."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6697cab3-e8b3-4cce-9003-6f497ab446e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a8abaa-f64f-4380-9828-10260ea778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "sys.path.append('..')  # import tests\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ans\n",
    "from tests import test_convolutional_network\n",
    "from tests.test_neural_library import randn_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813cac1a-eb5d-4301-806f-ac399d2d4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile='short')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737310a-d782-441d-bf52-b7b19294c3a4",
   "metadata": {},
   "source": [
    "# Dvourozměrná konvoluce jako diferencovatelná funkce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac7c06-b8e3-4842-b1e0-0c1fc8e8050f",
   "metadata": {},
   "source": [
    "Konvoluci nejprve naimplementujeme jako diferencovatelnou operaci odvozenou od třídy `ans.funcitonal.Function`.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    z_{n,f,u,v} & = \\sum_{c=1}^{C}\\sum_{i=1}^{K}\\sum_{j=1}^{K}{ w_{f,c,i,j} \\cdot x_{n, c, D \\cdot i + S \\cdot u, D \\cdot j + S \\cdot v} + b_f } \\\\\n",
    "    % \\forall (f, u, v) & \\in \\{1, ..., F\\} \\times \\{1, ..., Q\\} \\times \\{1, ..., Q\\} \\\\\n",
    "    % Q & = \\lfloor \\frac{M + 2 \\cdot P - K}{S} \\rfloor + 1\n",
    "\\end{split}\n",
    "$$\n",
    "- $x_{n,c,i,j}$ je jeden prvek tensoru vstupu $\\boldsymbol{x} = [x_{n,c,i,j}]$ s rozměry $N \\times C \\times M \\times M$\n",
    "- $N$ je velikost dávky, tj. počet \"obrázků\" ve vstupním tensoru $\\boldsymbol{x}$\n",
    "- $M$ je výška a šířka tensoru vstupu $\\boldsymbol{x}$; pro jednoduchost předpokládáme čtvercový vstup, tj. např. $224 \\times 224$\n",
    "- $C$ je počet kanálů tensoru vstupu $\\boldsymbol{x}$; např. pro RGB je $C = 3$\n",
    "- $w_{f,c,i,j}$ je jeden prvek váhového tensoru $\\boldsymbol{w} = [w_{f,c,i,j}]$ o rozměrech $F \\times C \\times K \\times K$\n",
    "- $K$ je velikost konvolučního filtru; pro jednoduchost předpokládáme čtvercový tvar, např. $3 \\times 3$\n",
    "- $F$ je celkový počet konvolučních filtrů\n",
    "- $b_f$ je jeden prvek vektoru biasů $\\boldsymbol{b} = [b_1, \\ldots, b_F]$ o rozměru $F$; vychází tedy jeden bias (skalár) na každý z $F$ filtrů\n",
    "- $z_{n,f,u,v}$ je jeden prvek výstupního tensoru $\\boldsymbol{z} = [z_{n,f,u,v}]$ s rozměry $N \\times F \\times Q \\times Q$\n",
    "\n",
    "Pro rozměr výstupu $Q$ platí\n",
    "$$\n",
    "Q = \\left\\lfloor \\frac{M + 2 \\cdot P - K}{S} \\right\\rfloor + 1\n",
    "$$\n",
    "- $S$ je *hyperparametr* a značí krok (stride)\n",
    "- $P$ je *hyperparametr* a značí, o kolik nul je nutné nastavit vstup v prostorových dimenzích (padding)\n",
    "- $D$ je *hyperparametr* a značí dilataci (dilation)\n",
    "\n",
    "Vstup je nastaven o nulové hodnoty, tzn. že platí\n",
    "$$\n",
    "x_{n, c, i \\lt 1, j \\lt 1} = x_{n, c, i \\gt M, j \\gt M} = 0\n",
    "$$\n",
    "\n",
    "Celou operaci konvoluce, kdy se vztah $z_{n,f,u,v} = \\ldots$ vyhodnotí pro všechny $(f,u,v)$ (všechny prvky tensoru $\\boldsymbol{z}_n$), zkráceně zapíšeme jako\n",
    "$$\n",
    "\\boldsymbol{z}_n = \\textrm{conv2}\\left( \\boldsymbol{x}_n, \\boldsymbol{w}, \\boldsymbol{b}; S, P, D \\right)\n",
    "$$\n",
    "- $\\boldsymbol{x}_n$ je $n$-tý \"obrázek\" dávky jako tensor s rozměry $C \\times M \\times M$\n",
    "- $\\boldsymbol{z}_n$ je $n$-tý výstup dávky jako tensor s rozměry $F \\times Q \\times Q$\n",
    "\n",
    "**Zpětný průchod**\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\overline{x}_{n,c,i,j} & = \\sum_{f=1}^{F}\\sum_{u=1}^{Q}\\sum_{v=1}^{Q}{ \\overline{z}_{n,f,u,v} \\cdot w_{f, c, D \\cdot i - S \\cdot u, D \\cdot j - S \\cdot v} } \\\\\n",
    "    \\overline{w}_{f,c,i,j} & = \\sum_{n=1}^N\\sum_{u=1}^{Q}\\sum_{v=1}^{Q}{ \\overline{z}_{n,f,u,v} \\cdot x_{n, c, D \\cdot i + S \\cdot u, D \\cdot j + S \\cdot v} } \\\\\n",
    "    \\overline{b}_f & = \\sum_{n=1}^N\\sum_{u=1}^{Q}\\sum_{v=1}^{Q}{ \\overline{z}_{n,f,u,v} }\n",
    "\\end{split}\n",
    "$$\n",
    "- $\\overline{\\boldsymbol{z}}_n$ je příchozí gradient na výstup $\\boldsymbol{z}_n$ jako tensor s rozměry $F \\times Q \\times Q$\n",
    "\n",
    "Zkráceně lze zapsat zpětný průchod jako\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\overline{\\boldsymbol{x}}_n & = \\textrm{conv2}^\\top(\\overline{\\boldsymbol{z}}_n, \\boldsymbol{w}, \\boldsymbol{0}; S, P, D) \\\\\n",
    "    \\boldsymbol{\\overline{w}}_{f,c} & = \\sum_{n=1}^N{ \\textrm{conv2}(\\boldsymbol{x}_{n,c}, \\overline{\\boldsymbol{z}}_{n,f}, \\boldsymbol{0}; D, P, S) }\n",
    "\\end{split}\n",
    "$$\n",
    "- $\\textrm{conv2}^\\top(\\cdot)$ je tzv. transponovaná dvourozměrná konvoluce\n",
    "- $\\boldsymbol{x}_{n,c}$ je $c$-tý kanál $n$-tého vstupu jako matice s rozměry $M \\times M$\n",
    "- $\\overline{\\boldsymbol{z}}_{n,f}$ je příchozí gradient na $f$-tý kanál $n$-tého výstupu jako tensor s rozměry $Q \\times Q$\n",
    "- $\\boldsymbol{\\overline{w}}_{f,c}$ je vypočítáný gradient na $c$-tý kanál $f$-tého filtru jako matice s rozměry $K \\times K$\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Vzhledem ke složitosti a výpočetní náročnosti nebudeme funkce $\\textrm{conv2}(\\cdot)$ a $\\textrm{conv2}^\\top(\\cdot)$ implementovat vlastními silami pomocí for cyklů ani komplikovaného broadcastingu, ale použijeme funkce `conv2d`, resp. `conv_transpose2d` modulu `torch.nn.functional` knihovny Pytorch. Není to vyžadováno, ale gradient na váhy $\\boldsymbol{\\overline{w}}$ lze získat i zcela bez použití cyklů.\n",
    "\n",
    "*Output padding u `conv_transpose2d` pro výpočet gradientu na vstup:* \n",
    "\n",
    "- Pokud je stride $S \\gt 1$, může se stát, že z různě velkých vstupů $\\boldsymbol{x}_n$, $\\boldsymbol{x}_m$ funkcí vzniknou stejně velké výstupy $\\boldsymbol{z}_n$, resp. $\\boldsymbol{z}_m$. Pokud potom použijeme $\\textrm{conv2}^\\top$ jako zpětný průchod pro výpočet gradientu na vstup $\\overline{\\boldsymbol{x}}_n$, není rozměr výsledného gradientu na vstup jednoznačně určená, a tak $\\overline{\\boldsymbol{x}}_n$ nemusí svou velikostí přesně odpovídat $\\boldsymbol{x}$. Funkce `torch.nn.conv_transpose2d` proto zavádí argument `output_padding`, který výstup nastaví o požadovanou hodnotu. Aby měl $\\overline{\\boldsymbol{x}}_n$ rozměry shodné s $\\boldsymbol{x}_n$ a procházely všechny testy, je nutné `output_padding` dopočítat jako\n",
    "$$\n",
    "% (Q - 1) \\cdot S - 2 \\cdot P + D \\cdot (K - 1) + O + 1 = M \\\\\n",
    "O = M - (Q - 1) \\cdot S + 2 \\cdot P - (K - 1) \\cdot D - 1\n",
    "$$\n",
    "- a to *v obou dimenzích*, tj. pro výšku i šířku.\n",
    "\n",
    "*Oříznutí gradientu na váhy:*\n",
    "\n",
    "- U gradientu na váhy je situace o něco jednodušší. Může se stát, že výstup konvoluce $\\boldsymbol{\\overline{w}}_{f,c} = \\textrm{conv2}(\\boldsymbol{x}_{n,c}, \\overline{\\boldsymbol{z}}_{n,f}, \\ldots)$ vyjde větší než $K \\times K$. V takovém případě stačí výsledek o přebytečné hodnoty \"zdola\" a \"zprava\" oříznout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff01f9-3d0d-48d6-adaf-ec7ec73be56b",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.Conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9167b6d9-545b-49dc-b7bd-b8b564fa6174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinput ok: rel_err=2.068e-11, abs_err=4.117e-13\n",
      "dweight ok: rel_err=4.793e-13, abs_err=9.575e-13\n",
      "dbias ok: rel_err=3.912e-14, abs_err=6.022e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run with various params\n",
    "ans.autograd.gradcheck(\n",
    "    ans.functional.Conv2d.apply,\n",
    "    (\n",
    "        randn_var(7, 2, 5, 9, name='input'),\n",
    "        randn_var(4, 2, 3, 3, name='weight'),\n",
    "        randn_var(4, name='bias')\n",
    "    ),\n",
    "    params=dict()\n",
    "    # params=dict(stride=2)\n",
    "    # params=dict(stride=2, padding=1, dilation=2)\n",
    "    # params=dict(stride=2, padding=1, groups=2)  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7565f7-1f5d-4a43-9984-283508a056d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_backward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_backward) ... ok\n",
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... ok\n",
      "test_implementaiton (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementaiton) ... ok\n",
      "test_output_types (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_output_types) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 23.756s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_backward can take a while due to slow numeric_gradient\n",
    "test_convolutional_network.TestConv2dFunction.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0655f-7de7-4e70-a561-d2f3fcca1878",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dvourozměrná konvoluce jako vrstva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc7562-d0d5-4630-b42a-fed470b30fc4",
   "metadata": {},
   "source": [
    "Podobně jako všechny ostatní diferencovatelné operace i dvourozměrnou konvoluci vytvoříme i jako vrstvu typu `ans.modules.Module`. Vrstva `Conv2d` by měla:\n",
    "- uchovávat v sobě a v metodě `__init__` automaticky vhodně inicializovat parametry $\\boldsymbol{w}$ a $\\boldsymbol{b}$, tedy váhy a bias konvoluce\n",
    "- v dopředném průchodu `forward` vypočítat výstup jako $\\boldsymbol{z}_n = \\textrm{conv2}\\left( \\boldsymbol{x}_n, \\boldsymbol{w}, \\boldsymbol{b}; S, P, D \\right)$ (viz výše)\n",
    "\n",
    "**Inicializace vah**\n",
    "\n",
    "- Inicializovat váhy budeme podobně jako u lineární vrstvy, tj. jednou z variant metody Xavier, tak, [jak je tomu v knihovně v PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). Prvky váhového tensoru $\\boldsymbol{w} = [w_{fcij}]$ s rozměry $F \\times C \\times K \\times K$ navzorkujeme z rovnoměrného náhodného rozdělení\n",
    "$$\n",
    "w_{fcij} \\sim \\mathcal{U}\\left(\\frac{-1}{\\sqrt{CK^2}}, \\frac{+1}{\\sqrt{CK^2}}\\right)\n",
    "$$\n",
    "- Použijeme k tomu metodu [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html). Výsledný váhový tensor musí být atribut typu `Variable`.\n",
    "\n",
    "**Inicializace biasu**\n",
    "\n",
    "- Bias bude nepovinný parametr a příp. jej inicializujeme na nuly metodou [`torch.zeros`](https://pytorch.org/docs/stable/generated/torch.zeros.html). Výsledný vektor musí být atribut typu `Variable`, příp. objekt `None`, pokud je do `__init__` předáno `bias=False`.\n",
    "\n",
    "**Dopředný průchod**\n",
    "- Dopředný průchod `Conv2d.forward` by měl volat `ans.functional.Conv2d.apply`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda2b00-b8c2-47c4-9751-442a40c5e32b",
   "metadata": {},
   "source": [
    "### TODO: implementujte vrstvu `ans.modules.Conv2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1171f4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... ok\n",
      "test_implementaiton (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementaiton) ... ok\n",
      "test_init (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_init) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.060s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestConv2dModule.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3dff28-ab4e-42b1-9aec-ce458a8f8bc4",
   "metadata": {},
   "source": [
    "## Rectified Linear Unit (ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6fa22b-920b-47a0-87ce-8ba8c0b0838e",
   "metadata": {},
   "source": [
    "Sigmoid nelinearita nemá příliš vhodné vlastnosti pro zpětnou propagaci a u hlubokých konvolučních sítí může poměrně významně snižovat potenciální úspěšnost modelu. Efektivnější se z tohoto pohledu se ukázala rektifikovaná lineární jednotka, tzv. ReLU., bez které se na rozdíl od [multilayer-perceptron](multilayer-perceptron.ipynb) tentokrát již neobejdeme.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "z = \\begin{cases}\n",
    "    0 & \\textrm{pokud} & x \\le 0 \\\\\n",
    "    x & \\textrm{pokud} & x \\gt 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "- $x$ je reálné číslo (skalár)\n",
    "- $z$ je reálně číslo (skalár)\n",
    "\n",
    "**Zpětný průchod**\n",
    "\n",
    "$$\n",
    "\\overline{x} = \\begin{cases}\n",
    "    0 & \\textrm{pokud} & x \\le 0 \\\\\n",
    "    \\overline{z} & \\textrm{pokud} & x \\gt 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "- $\\overline{z}$ je příchozí gradient na $z$\n",
    "\n",
    "**Dávkové zpracování**\n",
    "\n",
    "Operaci ReLU aplikujeme na všechny prvky vstupu nezávisle na sobě.\n",
    "\n",
    "**Poznámka**\n",
    "\n",
    "Jelikož operace ReLU není diferencovatelná, numerický gradient se pro malé hodnoty $x \\approx 0$ kolem bodu zlomu v nule nechová jako subgradient a nevychází \"správně\". Pokud vám `gradcheck` v testu selže i přes podle vás správnou implementaci zpětného průchodu, zkuste ho opakovat. Pravděpodobnost selhávajícího testu je cca 27 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d2818-9a5e-42a0-854b-a14f3bceed42",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.ReLU` a vrstvu `ans.modules.ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d305a5f4-8a76-408a-8774-fd1e666505f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mdinput FAIL: rel_err=1.000e+00, abs_err=1.238e-01\n",
      "\n",
      "Analytic gradient: \n",
      "tensor([[-0.00, -0.00,  2.26,  0.00],\n",
      "        [-1.00,  1.33,  0.17, -0.25],\n",
      "        [ 0.00,  0.00, -0.70, -1.74],\n",
      "        [ 0.00, -0.00,  0.00,  0.00],\n",
      "        [ 0.00, -0.69, -0.00,  0.00],\n",
      "        [-0.31,  0.00,  0.00,  0.00],\n",
      "        [ 0.67, -0.00, -1.33, -0.14],\n",
      "        [ 0.00, -0.70, -0.00, -0.51]], dtype=torch.float64) \n",
      "\n",
      "Numeric gradient: \n",
      "tensor([[ 0.00,  0.00,  2.26,  0.00],\n",
      "        [-1.00,  1.33,  0.17, -0.25],\n",
      "        [ 0.00,  0.00, -0.70, -1.74],\n",
      "        [ 0.00,  0.00,  0.00,  0.00],\n",
      "        [ 0.12, -0.69,  0.00,  0.00],\n",
      "        [-0.31,  0.00,  0.00,  0.00],\n",
      "        [ 0.67,  0.00, -1.33, -0.14],\n",
      "        [ 0.00, -0.70,  0.00, -0.51]], dtype=torch.float64) \n",
      "\n",
      "Relative error: \n",
      "tensor([[0.00e+00, 0.00e+00, 6.89e-15, 0.00e+00],\n",
      "        [6.91e-15, 1.84e-15, 3.22e-16, 1.70e-15],\n",
      "        [0.00e+00, 0.00e+00, 1.73e-15, 1.66e-15],\n",
      "        [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "        [1.00e+00, 1.77e-15, 0.00e+00, 0.00e+00],\n",
      "        [7.01e-15, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "        [4.98e-16, 0.00e+00, 1.67e-15, 1.77e-15],\n",
      "        [0.00e+00, 6.99e-15, 0.00e+00, 1.74e-15]], dtype=torch.float64)\n",
      "\u001b[30m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    ans.functional.ReLU.apply,\n",
    "    (\n",
    "        randn_var(8, 4, std=10., name='input'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f771b38-9fe2-42f5-ba68-0698c62278a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_function (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_function) ... ok\n",
      "test_forward_module (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_module) ... ok\n",
      "test_gradcheck (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_gradcheck) ... ok\n",
      "test_implementation (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementation) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.085s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestReLU.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ccac4-79ff-4b00-93fd-a7551a05c258",
   "metadata": {},
   "source": [
    "# Max-pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998724c",
   "metadata": {},
   "source": [
    "Téměř nedílnou součástí konvolučních sítí jsou tzv. [pooling vrstvy](https://d2l.ai/chapter_convolutional-neural-networks/pooling.html). Implementujeme si jednu z nejčastějších, tzv. max-pooling.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "z_{n,c,u,v} = \\max_{i=1,\\ldots,K}\\max_{j=1,\\ldots,K}{x_{n,c,K \\cdot (u-1)+i,K \\cdot (v-1)+j}}\n",
    "$$\n",
    "- $x_{n,c,k,l}$ je jeden prvek tensoru vstupu $\\boldsymbol{x} = [x_{n,c,k,l}]$ s rozměry $N \\times C \\times M \\times M$\n",
    "- $N$ je velikost dávky, tj. počet \"obrázků\" ve vstupním tensoru $\\boldsymbol{x}$\n",
    "- $M$ je výška a šířka tensoru vstupu $\\boldsymbol{x}$; pro jednoduchost předpokládáme čtvercový vstup, tj. např. $224 \\times 224$\n",
    "- $C$ je počet kanálů tensoru vstupu $\\boldsymbol{x}$; např. pro RGB je $C = 3$\n",
    "- $K$ je velikost okolí pro pooling; pro jednoduchost předpokládáme čtvercový tvar, např. $2 \\times 2$\n",
    "- $z_{n,c,u,v}$ je jeden prvek výstupního tensoru $\\boldsymbol{z} = [z_{n,c,u,v}]$ s rozměry $N \\times C \\times Q \\times Q$\n",
    "- indexování prvků začíná jedničkou\n",
    "\n",
    "Abychom replikovali chování `MaxPool2d` knihovny, pro velikost výstupu bude platit\n",
    "$$\n",
    "Q = \\left\\lfloor\\frac{M}{K}\\right\\rfloor\n",
    "$$\n",
    "To znamená, že v případech, kdy velikost vstupu $M$ není dělitelná velikostí okna $K$, nadbytečné hodnoty ve vstupu $\\boldsymbol{x}$ budeme ignorovat.\n",
    "\n",
    "**Zpětný průchod**\n",
    "$$\n",
    "% \\overline{x}_{n,c,Ku+k,Kv+l} = \\begin{cases}\n",
    "%     \\overline{z}_{n,c,u,v} & \\textrm{pokud} & x_{n,c,Ku+k,Kv+l} = \\max_{i=1,\\ldots,K}\\max_{j=1,\\ldots,K}{x_{n,c,Ku+i,Kv+j}} \\\\\n",
    "%     0 & \\textrm{jinak}\n",
    "% \\end{cases}\n",
    "\\overline{x}_{n,c,k,l} = \\begin{cases}\n",
    "    \\overline{z}_{n,c,u,v} & \\textrm{pokud} & x_{n,c,k,l} = \\max_{i=1,\\ldots,K}\\max_{j=1,\\ldots,K}{x_{n,c,K\\cdot u+i,K\\cdot v+j}} \\\\\n",
    "    0 & \\textrm{jinak}\n",
    "\\end{cases}\n",
    "$$\n",
    "- $u = \\lfloor \\frac{k-1}{K} \\rfloor$, $v = \\lfloor\\frac{l-1}{K}\\rfloor$\n",
    "- $\\overline{\\boldsymbol{z}} = [\\overline{z}_{n,c,u,v}]$ je příchozí gradient na výstup $\\boldsymbol{z}$ jako tensor s rozměry $N \\times C \\times Q \\times Q$\n",
    "- $\\overline{x}_{n,c,k,l}$ je jeden prvek (skalár) gradientu na vstup $\\overline{\\boldsymbol{x}}$\n",
    "- celkový gradient na vstup $\\overline{\\boldsymbol{x}}$ je tensor s rozměry $N \\times C \\times M \\times M$\n",
    "\n",
    "Všechny prvky vstupu $\\boldsymbol{x}$, které v dopředném průchodu vykázaly maximální hodnotu ve svém lokálním okolí o velikosti $K \\times K$, mají gradient roven příchozímu gradientu na odpovídající pozici. Ostatní prvky vstupu $\\boldsymbol{x}$ mají gradient nulový.\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Oproti možnostem v knihovně PyTorch si redukujeme počet hyperparametrů a ponecháme pouze velikost pooling okolí $K$ pod jménem `window_size` (v PyTorch se parametr nazývá `kernel_size`). Tento parametr bude celé číslo, tzn. že se omezíme na čtvercové okno o roměru $K \\times K$.\n",
    "\n",
    "*Operaci naprogramujte vektorově bez použití cyklů!*\n",
    "- Např. max-pooling vektoru s velikostí okna `window_size=2`:\n",
    "``` python\n",
    ">>> x = torch.tensor([1, 2, 4, 3, 5, 5])\n",
    ">>> x.reshape(3, 2).max(dim=1)\n",
    "(tensor([2, 4, 5]), tensor([1, 0, 0]))\n",
    "```\n",
    "- U dvourozměrného vstupu je potřeba obdobný reshape provést pro výšku i šířku.\n",
    "- Hodit se může také funkce `torch.transpose`, pomocí které lze posunout přidané dimenze na poslední dvě místa, což umožní reshape na `(..., window_size * window_size)`.\n",
    "\n",
    "**Max-pooling jako vrstva**\n",
    "\n",
    "Vrstva `MaxPool2d` v metodě `__init__` převezme velikost pooling okna $K$ jako parametr `window_size` a v dopředném průchodu pouze zavolá `ans.functional.MaxPool2d.apply`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ec58b-bae0-443a-9495-effe30c6a23a",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.MaxPool2d` a vrstvu `ans.modules.MaxPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f24318-45a3-4729-923e-f6d7603d0c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:676: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(output)\n",
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:677: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinput ok: rel_err=2.110e-12, abs_err=3.388e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    ans.functional.MaxPool2d.apply,\n",
    "    (\n",
    "        randn_var(5, 3, 4, 7, name='input'),\n",
    "    ),\n",
    "    params=dict(window_size=3),\n",
    "    eps=1e-4  # minimize risk of fail\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d5876c-f2f3-428c-ba85-19dd3f72198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_backward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_backward) ... C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:676: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(output)\n",
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:677: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices)\n",
      "ok\n",
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... ok\n",
      "test_implementaiton (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementaiton) ... ok\n",
      "test_output_types (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_output_types) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 1.905s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestMaxPool2dFunction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f785ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:676: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(output)\n",
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:677: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices)\n",
      "ok\n",
      "test_implementaiton (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementaiton) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestMaxPool2dModule.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc5871-b7ca-4d3b-a22c-c52d31fecd02",
   "metadata": {},
   "source": [
    "# Operace `Variable.reshape`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db960d19",
   "metadata": {},
   "source": [
    "Poslední operací potřebnou pro konvoluční sítě je reshape $N \\times F \\times M \\times M$-rozměrného výstupu konvoluce do rozměrů $N \\times D$, kde\n",
    "- $N$ je počet vstupů v dávce\n",
    "- $D = F \\cdot M^2$ je dimenze příznaků.\n",
    "\n",
    "Takto přetvarovaná data můžeme snadno klasifikovat pomocí lineární vrstvy `Linear` např. do 10 tříd tak, abychom v každém řádku získali 10 klasifikačních skóre (logitů) podobně jako ve cvičeních [`linear-classification`](linear-classification.ipynb) a [`multilayer-perceptron`](multilayer-perceptron.ipynb). Operaci si zadefinujeme jako obecné přetvarování tensoru.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "$$\n",
    "% \\begin{split}\n",
    "\\boldsymbol{z} = \\textrm{reshape}(\\boldsymbol{x}; F_1, \\ldots, F_Z) \\\\\n",
    "% \\textrm{tak, aby} \\; F_1 \\cdot \\ldots \\cdot F_Z = D_1 \\cdot \\ldots \\cdot D_X\n",
    "% \\end{split}\n",
    "$$\n",
    "- $\\boldsymbol{x}$ je vstupní tensor o libovolných rozměrech $D_1 \\times \\ldots \\times D_X$\n",
    "- $\\boldsymbol{z}$ je výstupní tensor o rozměru $F_1 \\times \\ldots \\times F_Z$\n",
    "\n",
    "Pokud $\\prod_{i=1}^{F_Z}F_i \\ne \\prod_{i=1}^{D_X}D_i$ (nesedí počet prvků), funkce vyhodí výjimku typu `RuntimeError`.\n",
    "\n",
    "**Zpětný průchod**\n",
    "\n",
    "$$\n",
    "\\overline{\\boldsymbol{x}} = \\textrm{reshape}(\\overline{\\boldsymbol{z}}; D_1, \\ldots, D_X)\n",
    "$$\n",
    "- $\\overline{\\boldsymbol{z}}$ je příchozí gradient na výstup jako tensor o rozměrech $F_1 \\times \\ldots \\times F_Z$\n",
    "- $\\overline{\\boldsymbol{x}}$ je výsledný gradient na vstupní tensor $\\boldsymbol{x}$ o rozměrech $D_1 \\times \\ldots \\times D_X$\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Místo odvozování z typu `ans.functional.Function` si vzhledem k její jednoduchosti operaci implementujeme přímo ve třídě `Variable` metodou `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4f3349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinput ok: rel_err=1.879e-14, abs_err=2.731e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    lambda var: var.reshape(5, 3 * 4, 7),\n",
    "    # lambda var: var.reshape(5, 3, 4 * 7),\n",
    "    (\n",
    "        randn_var(5, 3, 4, 7, name='input'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1599fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_backward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_backward) ... ok\n",
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... ok\n",
      "test_implementaiton (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementaiton) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 1.127s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestReshape.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d2c79",
   "metadata": {},
   "source": [
    "# Vrstva `Flatten`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb85d9",
   "metadata": {},
   "source": [
    "Po vzoru PyTorch si rovněž zadefinujeme vrstvu `Flatten`, což nám umožní jednoduše vkládat tuto operaci např. do `Sequential`. Operace provede\n",
    "$$\n",
    "\\boldsymbol{z} = \\textrm{reshape}(\\boldsymbol{x}; N, D)\n",
    "$$\n",
    "- $\\boldsymbol{x}$ je vstupní tensor o rozměrech $N \\times D_2 \\times \\ldots \\times D_X$\n",
    "- $\\boldsymbol{z}$ je výstupní tensor o rozměrech $N \\times D$, kde $D = \\prod_{i=2}^{D_X}D_i$\n",
    "\n",
    "\n",
    "\n",
    "**Inicializace**\n",
    "\n",
    "- Vrstva nebude definovat metodu `__init__` a tudíž bude cela bez parametrů.\n",
    "\n",
    "**Dopředný průchod**\n",
    "\n",
    "- Dopředný průchod bude volat metodu `Variable.reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc4e4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... ok\n",
      "test_implementaiton (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementaiton) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestFlattenModule.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba9329",
   "metadata": {},
   "source": [
    "# Model konvoluční sítě VGG7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebbd85",
   "metadata": {},
   "source": [
    "Nyní máme zadefinovány operace související s dvourozměrnou konvolucí jako funkční bloky a zbývá nám navrhnout celkový mode sítě. Můžeme přitom využít všechny ostatní operace z minulých úloh jako např. lineární vrstvu. Jelikož hledání ideální konvoluční architektury metodou pokus omyl by mohlo být časově náročné, budeme implementovat jednu konkrétní architekturu odvozenou z [VGG](https://arxiv.org/abs/1409.1556). Síť bude vypadat následovně:\n",
    "\n",
    "`CR(64), M(2), CR(128), M(2), CR(256), M(2), CR(512), M(2), CR(512), M(2), LR(512), L(10)`\n",
    "\n",
    "kde:\n",
    "- např. `CR(64)` znamená dvourozměrnou konvoluci (`C`) se 64 filtry a biasy následovanou ReLU (`R`); všechny konvoluce mají velikost 3x3\n",
    "- `M(2)` znamená max-pooling s oknem o velikosti 2 a krokem 2\n",
    "- `LR(512)` znamená lineární vrstvu (`L`) následovanou ReLU (`R`) s *výstupním* vektorem o rozměru 512\n",
    "\n",
    "Konvoluční síť po vzoru článku od Simonyan & Zisserman pojmenujeme jako VGG7, protože má 7 vrstev s trénovatelnými parametry. Model zadefinujeme jako třídu `VGG7` odvozenou z `ans.modules.Module`. Třída `VGG7` by měla:\n",
    "- v `__init__` zadefinovat potřebné operace jako své atributy typu `ans.modules.Module`\n",
    "- ve `forward` zavolat své vrstvy ve správném pořadí na vstup typu `ans.autograd.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfa14e",
   "metadata": {},
   "source": [
    "### TODO: Implementuje model konvoluční sítě VGG7 jako třídu `VGG7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d30aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ans.modules as nn\n",
    "import ans.autograd as ag\n",
    "\n",
    "class VGG7(ans.modules.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(window_size=2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(512, 512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################\n",
    "    \n",
    "    # feel free to add auxiliary methods here\n",
    "    # def my_function(...)\n",
    "    \n",
    "    def forward(self, x: ans.autograd.Variable) -> ans.autograd.Variable:\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten for linear layers\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu6(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "        # ENDTODO\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476d97a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:676: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(output)\n",
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:677: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices)\n",
      "ok\n",
      "test_num_params (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_num_params) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.381s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestVGG7.eval(model_cls=VGG7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a945e8-23b5-4a9e-ab2c-c2a84050d556",
   "metadata": {},
   "source": [
    "# Načtení dat a příprava dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6befc-be48-4b12-8946-8bc3b31a0956",
   "metadata": {},
   "source": [
    "Oproti minulým cvičením trochu pozměníme práci s daty a namísto `ans.data.BatchLoader` využijeme `torch.utils.data.DataLoader`. Vynecháme rovněž vlastní implementaci funkce `preprocess` a uvolníme tak prostor pro využití již hotových transformací z modulu `torchvision.transforms`. To vše nám později umožní jednoduše augmentovat data pro zvýšení klasifikační úspěšnosti.\n",
    "\n",
    "Preprocessing lze přidat přidat přímo do objektu `CIFAR10` argumentem `transform`, kterým typicky bývá sekvence typu `torchvision.transforms.Compose`. Třída `Compose` převezme `list` operací, které při zavolání na vstup jednu po druhé aplikuje. Děje se tak přitom automaticky v objektu datasetu `CIFAR10` vždy předtím, než daný obrázek vrátí jako vzorek.\n",
    "\n",
    "Předáme pro začátek pouze dvě operace, kterými bude každý obrázek modifikován:\n",
    "1. `torchvision.transforms.ToTensor()` převede obrázek z `numpy.ndarray` se `shape=(H, W, C)` a `dtype=numpy.uint8` (rozsah 0..255) na `torch.Tensor` se `shape=(C, H, W)` a `dtype=torch.float32` (rozsah 0..1),\n",
    "2. `torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))` odečte od každé trojice RGB hodnot (pixelu) vektor `(0.485, 0.456, 0.406)` a vydělí `(0.229, 0.224, 0.225)`. Hodnoty jsou vypočtené jako očekávaná hodnota a standardní odchylka RGB pixelů na datasetu ImageNet a zajišťují, že vstupní tensory do sítě mají přibližně nulový průměr a jednotkový rozptyl v RGB. Shodná čísla používají veškeré předtrénované modely v modulu `torchvision.models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "823e97c7-f2ff-4ca0-860e-b4682b27d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "           )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = '../data',\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    download = True\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af4a34c-a139-42cc-b698-983fad73356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "           )"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = '../data',\n",
    "    train = False,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    download = True\n",
    ")\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d011ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), torch.float32, tensor(-0.19), tensor(0.82))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_dataset[0]\n",
    "x.shape, x.dtype, x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d430d2-4fbd-4054-8131-a00e3ae295b8",
   "metadata": {},
   "source": [
    "# Funkce pro trénování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de24e0f-f2ab-4ae0-84d3-56f4fbc5be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output linear scores (logits before softmax); shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        acc: average accuracy on the batch; tensor containing single number (scalar), e.g. \"tensor(0.364)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    if isinstance(scores, ag.Variable):  # Convert to Tensor\n",
    "        scores = scores.data\n",
    "    \n",
    "    _, predicted_classes = torch.max(scores, 1)\n",
    "    \n",
    "    correct_predictions = (predicted_classes == targets).float()\n",
    "    acc = torch.mean(correct_predictions)\n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8938965c-3f00-44ae-aca1-0113d3715983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_accuracy (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_accuracy) ... ok\n",
      "test_implementation (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementation) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestAccuracy.eval(accuracy_fn=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f78a86-fb3b-44b9-a4ca-d0c27649c796",
   "metadata": {},
   "source": [
    "Oproti cvičením [linear-classification](linear-classification.ipynb) a [multilayer-perceptron](multilayer-perceptron.ipynb) ve funkcích `train_step` a `val_step` nebudeme provádět `preprocess`, protože jsme jej refaktorovali přímo do datasetu, viz výše. Ostatní kroky zůstavají shodné. Opět nezapomeňte na `zero_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "721760d7-756b-45d1-b058-42bbc81a8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    model: ans.modules.Module,\n",
    "    criterion: ans.modules.Module,\n",
    "    optimizer: ans.optim.Optimizer,\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    loss.backprop()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    acc = accuracy(outputs, targets)\n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.data.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbee1614-7ad4-4a4d-a4ac-3b1cc2f3b916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    model: ans.modules.Module,\n",
    "    criterion: ans.modules.Module\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    acc = accuracy(outputs, targets)\n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.data.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c9f763-b693-4147-9f9f-0c2bb6d59835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_implementation (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementation) ... ok\n",
      "test_train_step (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_train_step) ... ok\n",
      "test_val_step (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_val_step) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.943s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestSteps.eval(train_step_fn=train_step, val_step_fn=val_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ec24c8-3435-46af-9e19-a9a6d13aa5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    loader: ans.data.BatchLoader,\n",
    "    model: ans.modules.Module,\n",
    "    criterion: ans.modules.Module\n",
    ") -> tuple[float, float]:\n",
    "    total_loss = 0.\n",
    "    total_acc = 0.\n",
    "    for inputs, targets in loader:\n",
    "        loss, acc = val_step(inputs, targets, model, criterion)\n",
    "        total_loss += loss\n",
    "        total_acc += acc\n",
    "    return total_loss / len(loader), total_acc / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784ff8d-c80e-4924-84fa-f9711b519a5d",
   "metadata": {},
   "source": [
    "# Hlavní cyklus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387b2b0",
   "metadata": {},
   "source": [
    "Na rozdíl od minulých cvičení je doporučeno trénovat na GPU, pokud vám je k dispozici. Jinak totiž mohou být konvoluční sítě poměrně pomalé a trénování zdlouhavé. V závislosti na konkrétním modelu a HW prostředcích může hlavní cyklus běhat 10x až cca 25x rychleji na GPU než na CPU. Přesun zajišťuje třída `ans.data.DataLoader`, která je odvozená od `torch.utils.data.DataLoader`.\n",
    "\n",
    "Pár poznámek k trénování:\n",
    "- Adam je tolerantnější a robustnější vůči neoptimálně navrženým hyperparametrům a v takových případech rychleji a lépe konverguje než SGD s momentum.\n",
    "- Není nezbytně nutné mnohahodinové trénování, přestože může pomoci \"vymačkat\" z modelu o několik procent více. K dosažení požadované validační úspešnosti 75 % může s dobře nastavenými hyperparametry (a ideálně s optimizérem Adam) stačit cca 5-6 epoch.\n",
    "- Pro začátek nepoužívejte regularizaci a klidně nechte model se přeučit. Není těžké příliš velkým koeficientem `weight_decay` optimalizaci hlavně na začátku trénování zpomalit až zastavit.\n",
    "- U konvolučních sítí s velkými dávkami (`batch_size`) se může při trénování na GPU vyčerpat VRAM. Pro takové případy je na začátku každé epochy zavolán garbage collector, který se pokusí odstranit z paměti dereferencované objekty, z nichž některé stále mohou držet ukazatele na již nepoužívané tensory a blokovat tak paměť GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547faca1-f80d-4fa4-87d4-d0c9cc6fe30e",
   "metadata": {},
   "source": [
    "### TODO: Natrénujte model VGG7 tak, aby dosáhl alespoň 75% úspěšnosti na validační sadě"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b5fbe49-a26a-4990-a4c4-cbad91c1225a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (double) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:42\u001b[0m\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(loader, model, criterion)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m----> 9\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     11\u001b[0m     total_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mval_step\u001b[1;34m(inputs, targets, model, criterion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mval_step\u001b[39m(\n\u001b[0;32m      2\u001b[0m     inputs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m      3\u001b[0m     targets: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     12\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy(outputs, targets)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 51\u001b[0m, in \u001b[0;36mVGG7.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(x)\n\u001b[0;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[1;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n\u001b[0;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(x)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:318\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:14\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *inputs, **params)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Union[Variable, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m     13\u001b[0m     tensor_args \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, Variable) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m---> 14\u001b[0m     output_data, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensor_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_fn\u001b[39m(dout: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m     17\u001b[0m         dinputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(dout, cache\u001b[38;5;241m=\u001b[39mcache)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:572\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    input: shape (num_samples(minibatch), num_channels(in_channels), height, width)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03m    cache: tuple of intermediate results to use in backward\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m#input = input.to('cpu')\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m#weight = weight.to('cpu')\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m#output = torch.nn.functional.conv2d(input, weight, bias=torch.tensor(bias), stride=stride, padding=padding, dilation=dilation, groups=groups)        \u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m cache \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28minput\u001b[39m, weight, bias, stride, padding, dilation, groups)\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# ENDTODO\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "import time\n",
    "import cProfile\n",
    "\n",
    "\n",
    "#def main():\n",
    "\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 7\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = VGG7(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ans.optim.Adam(model.parameters(), learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "#cProfile.run(\"main()\", sort=\"tottime\")\n",
    "\n",
    "    \n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2143bd46-5535-4deb-957e-2394ddadb8c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mbest_results(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m history\u001b[38;5;241m.\u001b[39mdf()\u001b[38;5;241m.\u001b[39mplot(secondary_y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.best_results('val_acc', 'max'))\n",
    "history.df().plot(secondary_y=['train_acc', 'val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e22a5b-b18f-4d28-aebd-622416c2fcf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Další vylepšení"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edebcf-cd06-4343-9987-bac9acaf6e62",
   "metadata": {},
   "source": [
    "Jako bonus můžete podobně jako ve cvičení [multilayer-perceptron](multilayer-perceptron.ipynb) opět zkusit trochu vylepšit skóre sítě. Implementujte postupně následující kroky, opakujte hlavní cyklus znovu a sledujte, zda a jak se mění výsledná přesnost na validační sadě (`val_acc`). Model by měl na konci snažení dosáhnout **alespoň 90% přesnosti** na validační množině."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22916f34-20d4-457b-8386-0d1e4d1b0b39",
   "metadata": {},
   "source": [
    "## Datová augmentace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17162fed",
   "metadata": {},
   "source": [
    "Jedním z problémů silnějších modelů se na jednodušších datasetech jako CIFAR10 může stát přeučení. Nejlepším řešením je v takovém případě nasbírat dodatečná data, což však mnohdy boužel není možné. Jako substituci ale můžeme vyzkoušet tzv. [datovou augmentaci](https://d2l.ai/chapter_computer-vision/image-augmentation.html#image-augmentation), která spočívá v umělém rozšířování datasetu pomocí náhodných transformací omezeného množství dat, která máme k dispozici.\n",
    "\n",
    "**Doporučené augmentace**\n",
    "\n",
    "V případě obrázků můžeme např. náhodně s pravěpodobností 50 % před vstupem do sítě obrázek horizontálně převrátit, jelikož všechny třídy v datasetu CIFAR10 jsou v tomto symetrické. Stejnou operaci bychom samozřejmě nemohli provádět např. pro číslovky datasetu MNIST. Další vhodnou náhodnou transformací pak může být např. náhodný ořez tak, aby se objekty tříd síti prezentovaly různě velké a také ne pouze uprostřed obrázku.\n",
    "\n",
    "**Implementace**\n",
    "\n",
    "Datovou augmentaci aplikujte pouze na trénovací data a to ještě před původním preprocessingem, který musí zůstat pro obě podmnožiny shodný. Použijte k tomu vhodné třídy dostupné v modulu `torchvision.transforms` a přidejte jejich instance na začátek pole `transform`, které vstupuje jako argument do `CIFAR10.__init__`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb9510",
   "metadata": {},
   "source": [
    "### TODO: přidejte do trénovací množiny libovolnou datovou augmentaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe75d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Compose(\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomCrop(size=(32, 32), padding=4)\n",
       "           )\n",
       "               Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "           )\n",
       "           )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(size=(32, 32), padding=4)\n",
    "])\n",
    "\n",
    "original_transform = transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "train_dataset_aug = torchvision.datasets.CIFAR10(\n",
    "    root = '../data',\n",
    "    train = True,\n",
    "    transform = transforms.Compose([\n",
    "        augmentation_transform,\n",
    "        original_transform\n",
    "    ]),\n",
    "    download = True\n",
    ")\n",
    "train_dataset_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "746299a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_train_dataset (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_train_dataset) ... ok\n",
      "test_val_dataset (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_val_dataset) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.069s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestAugmentation.eval(train_dataset=train_dataset_aug, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db65b520",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (double) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:37\u001b[0m\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(loader, model, criterion)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m----> 9\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     11\u001b[0m     total_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mval_step\u001b[1;34m(inputs, targets, model, criterion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mval_step\u001b[39m(\n\u001b[0;32m      2\u001b[0m     inputs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m      3\u001b[0m     targets: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     12\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy(outputs, targets)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 51\u001b[0m, in \u001b[0;36mVGG7.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(x)\n\u001b[0;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[1;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n\u001b[0;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(x)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:318\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:14\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *inputs, **params)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Union[Variable, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m     13\u001b[0m     tensor_args \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, Variable) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m---> 14\u001b[0m     output_data, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensor_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_fn\u001b[39m(dout: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m     17\u001b[0m         dinputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(dout, cache\u001b[38;5;241m=\u001b[39mcache)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:568\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m    input: shape (num_samples(minibatch), num_channels(in_channels), height, width)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03m    cache: tuple of intermediate results to use in backward\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m#output = torch.nn.functional.conv2d(input, weight, bias=torch.tensor(bias), stride=stride, padding=padding, dilation=dilation, groups=groups)        \u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m cache \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28minput\u001b[39m, weight, bias, stride, padding, dilation, groups)\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# ENDTODO\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 8\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset_aug,  # use augmented dataset\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = VGG7(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ans.optim.Adam(model.parameters(), learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e867f038",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mbest_results(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m history\u001b[38;5;241m.\u001b[39mdf()\u001b[38;5;241m.\u001b[39mplot(secondary_y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.best_results('val_acc', 'max'))\n",
    "history.df().plot(secondary_y=['train_acc', 'val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aec8f5-9015-40fd-802e-270e2a358afb",
   "metadata": {},
   "source": [
    "## Batch normalizace pro 2D vstupy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03809b",
   "metadata": {},
   "source": [
    "Pokud máte v knihovně `ans` implementovanou normalizaci dávky pro 1D vstupy z minulého cvičení, můžete ji poměrně jednoduše rozšířit pro 2D vstupy.  Tzv. spatial batchonrm, jak se často 2D varianta normalizace dávky označuje v anglické literatuře, *normalizuje přes jednotlivé kanály vstupu*. To znamená, že vektory $\\boldsymbol{\\mu}, \\boldsymbol{\\sigma^2}, \\boldsymbol{\\gamma}, \\boldsymbol{\\beta}, \\boldsymbol{m}, \\boldsymbol{v}^2$ jsou vektory o rozměru $C$. Operaci lze naimplementovat následovně:\n",
    "\n",
    "1. převedení vstupního tensoru $\\boldsymbol{x}$ s rozměry $N \\times C \\times H \\times W$ na 2D matici $(N \\cdot H \\cdot W) \\times C$,\n",
    "2. aplikace 1D batch normalizace\n",
    "3. převedení výstupní matice $(N \\cdot H \\cdot W) \\times C$ zpět do tensoru s rozměry $N \\times C \\times H \\times W$.\n",
    "\n",
    "*Pozor*: převedení tam i zpět nejsou pouhá přetvarování pomocí `reshape`.\n",
    "\n",
    "**Funkce `BatchNorm2d`**\n",
    "\n",
    "Jako funkce by \n",
    "- `BatchNorm2d.forward` měla volat `BatchNorm1d.forward` se správně upravenými vstupy,\n",
    "- `BatchNorm2d.backward` měla volat `BatchNorm1d.backward`  se správně upravenými vstupy.\n",
    "\n",
    "**Vrstva `BatchNorm2d`**\n",
    "\n",
    "Jako vrstva typu `ans.modules.Module` bude mít `BatchNorm2d`\n",
    "- metodu `__init__` shodnou s `BatchNorm1d`, takže ji není nutné implementovat\n",
    "- v metodě `forward` bude volat `ans.functional.BatchNorm2d.apply`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61188af",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `ans.functional.BatchNorm2d` a modul `ans.modules.BatchNorm2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6da581e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dinput ok: rel_err=1.325e-05, abs_err=1.079e-06\n",
      "dgamma ok: rel_err=3.528e-13, abs_err=1.670e-13\n",
      "dbeta ok: rel_err=2.235e-14, abs_err=1.119e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.autograd.gradcheck(\n",
    "    ans.functional.BatchNorm2d.apply,\n",
    "    (\n",
    "        randn_var(3, 4, 5, 8, mean=1., std=2., name='input'),\n",
    "        randn_var(4, name='gamma'),\n",
    "        randn_var(4, name='beta')\n",
    "    ),\n",
    "    params=dict(training=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4fb6ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_function_affine (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_function_affine) ... FAIL\n",
      "test_forward_function_linear (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_function_linear) ... FAIL\n",
      "test_forward_module (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_module) ... ok\n",
      "test_gradcheck (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_gradcheck) ... ok\n",
      "test_implementation (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_implementation) ... ok\n",
      "test_output_types (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_output_types) ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_forward_function_affine (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_function_affine)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\test_convolutional_network.py\", line 461, in test_forward_function_affine\n",
      "    self.assertTensorsClose(z_var.data, z, msg=f\"training[{i}]={training}\")\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\__init__.py\", line 108, in assertTensorsClose\n",
      "    self.fail(msg=f\"{msg}\\n{err_str}\")\n",
      "AssertionError: training[2]=False\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 4160 / 4160 (100.0%)\n",
      "Greatest absolute difference: 1.7172088722303256 at index (7, 1, 3, 4) (up to 0.0001 allowed)\n",
      "Greatest relative difference: 7265.08282749653 at index (2, 0, 1, 4) (up to 0.001 allowed)\n",
      "\n",
      "Actual\n",
      "tensor([[[[-0.46, -0.12,  ..., -0.60, -0.98],\n",
      "          [-1.27, -1.51,  ..., -0.90, -2.02],\n",
      "          ...,\n",
      "          [-0.29,  0.09,  ...,  0.54, -0.49],\n",
      "          [-0.96, -0.56,  ..., -0.36, -1.12]],\n",
      "\n",
      "         [[-1.87, -1.13,  ...,  0.58,  0.83],\n",
      "          [-0.60, -1.91,  ..., -1.41, -0.10],\n",
      "          ...,\n",
      "          [ 0.11, -2.45,  ...,  0.20,  0.51],\n",
      "          [-2.03, -1.55,  ..., -1.37,  0.35]],\n",
      "\n",
      "         [[-0.68, -0.39,  ..., -0.56, -0.72],\n",
      "          [-0.45, -0.42,  ..., -0.85, -0.14],\n",
      "          ...,\n",
      "          [-0.51, -0.26,  ..., -0.75, -0.39],\n",
      "          [-0.31, -0.61,  ..., -0.75, -0.75]],\n",
      "\n",
      "         [[-1.45, -2.15,  ...,  0.17,  0.16],\n",
      "          [-1.06,  0.53,  ..., -0.93,  0.64],\n",
      "          ...,\n",
      "          [ 1.02, -0.55,  ...,  0.76, -0.08],\n",
      "          [ 0.25, -2.22,  ..., -0.13, -1.17]]],\n",
      "\n",
      "\n",
      "        [[[-1.25,  0.10,  ..., -1.07,  0.03],\n",
      "          [-1.12, -0.06,  ..., -1.08, -0.26],\n",
      "          ...,\n",
      "          [-0.12, -1.24,  ..., -1.56, -0.59],\n",
      "          [-1.24, -0.94,  ..., -1.15, -0.48]],\n",
      "\n",
      "         [[-1.63, -0.17,  ...,  0.41,  0.12],\n",
      "          [ 0.39, -0.40,  ..., -1.68, -1.10],\n",
      "          ...,\n",
      "          [-2.28, -1.38,  ..., -1.82, -2.17],\n",
      "          [ 0.11,  0.91,  ..., -2.14, -1.06]],\n",
      "\n",
      "         [[-0.59, -0.76,  ..., -0.52, -0.54],\n",
      "          [-0.19, -0.65,  ..., -0.41, -0.66],\n",
      "          ...,\n",
      "          [-0.44, -0.32,  ..., -0.65, -0.43],\n",
      "          [-0.43, -0.70,  ..., -0.38, -0.78]],\n",
      "\n",
      "         [[ 0.55,  1.95,  ...,  0.16, -1.10],\n",
      "          [-0.64,  1.05,  ...,  1.56, -0.24],\n",
      "          ...,\n",
      "          [ 2.21,  0.59,  ...,  0.03, -0.60],\n",
      "          [ 0.86,  0.05,  ..., -1.05, -0.84]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.03, -0.85,  ..., -0.76, -2.08],\n",
      "          [-1.35, -1.05,  ..., -0.45, -1.21],\n",
      "          ...,\n",
      "          [-0.89, -0.14,  ..., -1.52, -1.62],\n",
      "          [-0.39, -0.46,  ..., -0.66, -0.99]],\n",
      "\n",
      "         [[ 0.70, -0.35,  ..., -1.97, -1.63],\n",
      "          [-2.28, -3.65,  ..., -1.47, -2.10],\n",
      "          ...,\n",
      "          [-0.62, -4.29,  ...,  0.16, -0.18],\n",
      "          [-0.94, -2.79,  ..., -0.02, -0.72]],\n",
      "\n",
      "         [[-1.23, -0.45,  ..., -0.54, -0.17],\n",
      "          [-0.56, -0.29,  ..., -0.35, -0.53],\n",
      "          ...,\n",
      "          [-0.86, -0.60,  ..., -0.73, -0.35],\n",
      "          [-0.88, -0.63,  ..., -0.36, -0.41]],\n",
      "\n",
      "         [[-0.04, -0.06,  ...,  0.01, -0.94],\n",
      "          [-1.24, -1.09,  ...,  0.31, -0.67],\n",
      "          ...,\n",
      "          [-0.56, -1.34,  ...,  0.29, -1.71],\n",
      "          [-1.53, -0.40,  ..., -1.85, -0.57]]],\n",
      "\n",
      "\n",
      "        [[[-0.83, -0.93,  ..., -0.87, -0.86],\n",
      "          [-1.15, -1.42,  ..., -0.94, -1.57],\n",
      "          ...,\n",
      "          [-0.13, -0.37,  ..., -0.63, -0.36],\n",
      "          [-1.63, -0.28,  ..., -1.21, -0.94]],\n",
      "\n",
      "         [[ 1.22, -3.41,  ..., -0.92, -1.46],\n",
      "          [ 0.57, -1.31,  ..., -2.61,  0.10],\n",
      "          ...,\n",
      "          [-0.32, -0.59,  ..., -0.97, -1.25],\n",
      "          [-0.45, -2.40,  ..., -0.07, -0.01]],\n",
      "\n",
      "         [[-0.57, -0.78,  ..., -0.54, -1.02],\n",
      "          [-0.29, -0.42,  ..., -1.05, -0.61],\n",
      "          ...,\n",
      "          [-0.62, -0.26,  ..., -0.59, -0.85],\n",
      "          [-0.71, -0.27,  ..., -0.40, -0.63]],\n",
      "\n",
      "         [[ 1.82,  1.39,  ..., -0.89,  2.06],\n",
      "          [ 0.18,  0.42,  ..., -0.85, -1.17],\n",
      "          ...,\n",
      "          [-0.21,  0.76,  ..., -0.09,  0.86],\n",
      "          [-0.11, -0.08,  ..., -0.63, -1.27]]]], dtype=torch.float64)\n",
      "\n",
      "Expected\n",
      "tensor([[[[-0.05,  0.26,  ..., -0.19, -0.54],\n",
      "          [-0.81, -1.04,  ..., -0.46, -1.52],\n",
      "          ...,\n",
      "          [ 0.10,  0.46,  ...,  0.88, -0.08],\n",
      "          [-0.52, -0.15,  ...,  0.03, -0.67]],\n",
      "\n",
      "         [[-0.57,  0.08,  ...,  1.57,  1.79],\n",
      "          [ 0.54, -0.61,  ..., -0.17,  0.97],\n",
      "          ...,\n",
      "          [ 1.16, -1.08,  ...,  1.24,  1.50],\n",
      "          [-0.71, -0.29,  ..., -0.14,  1.37]],\n",
      "\n",
      "         [[-0.46, -0.16,  ..., -0.34, -0.51],\n",
      "          [-0.23, -0.20,  ..., -0.65,  0.10],\n",
      "          ...,\n",
      "          [-0.29, -0.02,  ..., -0.54, -0.16],\n",
      "          [-0.08, -0.39,  ..., -0.54, -0.54]],\n",
      "\n",
      "         [[-1.15, -1.84,  ...,  0.45,  0.44],\n",
      "          [-0.76,  0.81,  ..., -0.64,  0.91],\n",
      "          ...,\n",
      "          [ 1.29, -0.27,  ...,  1.03,  0.20],\n",
      "          [ 0.53, -1.91,  ...,  0.15, -0.88]]],\n",
      "\n",
      "\n",
      "        [[[-0.79,  0.46,  ..., -0.63,  0.41],\n",
      "          [-0.67,  0.32,  ..., -0.63,  0.13],\n",
      "          ...,\n",
      "          [ 0.26, -0.79,  ..., -1.08, -0.18],\n",
      "          [-0.78, -0.50,  ..., -0.70, -0.07]],\n",
      "\n",
      "         [[-0.36,  0.92,  ...,  1.42,  1.16],\n",
      "          [ 1.40,  0.71,  ..., -0.40,  0.10],\n",
      "          ...,\n",
      "          [-0.93, -0.15,  ..., -0.53, -0.83],\n",
      "          [ 1.16,  1.86,  ..., -0.81,  0.14]],\n",
      "\n",
      "         [[-0.37, -0.55,  ..., -0.30, -0.32],\n",
      "          [ 0.05, -0.44,  ..., -0.18, -0.45],\n",
      "          ...,\n",
      "          [-0.22, -0.09,  ..., -0.44, -0.21],\n",
      "          [-0.21, -0.49,  ..., -0.15, -0.57]],\n",
      "\n",
      "         [[ 0.83,  2.21,  ...,  0.43, -0.80],\n",
      "          [-0.35,  1.32,  ...,  1.82,  0.04],\n",
      "          ...,\n",
      "          [ 2.47,  0.86,  ...,  0.31, -0.31],\n",
      "          [ 1.13,  0.33,  ..., -0.76, -0.55]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.59, -0.42,  ..., -0.34, -1.57],\n",
      "          [-0.89, -0.61,  ..., -0.05, -0.76],\n",
      "          ...,\n",
      "          [-0.45,  0.24,  ..., -1.05, -1.14],\n",
      "          [ 0.01, -0.06,  ..., -0.25, -0.55]],\n",
      "\n",
      "         [[ 1.68,  0.76,  ..., -0.66, -0.36],\n",
      "          [-0.93, -2.13,  ..., -0.23, -0.77],\n",
      "          ...,\n",
      "          [ 0.52, -2.68,  ...,  1.20,  0.91],\n",
      "          [ 0.24, -1.38,  ...,  1.05,  0.43]],\n",
      "\n",
      "         [[-1.04, -0.23,  ..., -0.32,  0.07],\n",
      "          [-0.34, -0.06,  ..., -0.12, -0.31],\n",
      "          ...,\n",
      "          [-0.66, -0.38,  ..., -0.52, -0.12],\n",
      "          [-0.67, -0.41,  ..., -0.13, -0.19]],\n",
      "\n",
      "         [[ 0.24,  0.22,  ...,  0.29, -0.65],\n",
      "          [-0.94, -0.79,  ...,  0.59, -0.39],\n",
      "          ...,\n",
      "          [-0.28, -1.04,  ...,  0.57, -1.41],\n",
      "          [-1.24, -0.11,  ..., -1.55, -0.28]]],\n",
      "\n",
      "\n",
      "        [[[-0.40, -0.49,  ..., -0.44, -0.43],\n",
      "          [-0.70, -0.96,  ..., -0.51, -1.10],\n",
      "          ...,\n",
      "          [ 0.25,  0.03,  ..., -0.22,  0.03],\n",
      "          [-1.15,  0.11,  ..., -0.76, -0.50]],\n",
      "\n",
      "         [[ 2.13, -1.92,  ...,  0.26, -0.22],\n",
      "          [ 1.56, -0.08,  ..., -1.21,  1.15],\n",
      "          ...,\n",
      "          [ 0.78,  0.55,  ...,  0.22, -0.03],\n",
      "          [ 0.67, -1.04,  ...,  1.00,  1.06]],\n",
      "\n",
      "         [[-0.35, -0.57,  ..., -0.32, -0.82],\n",
      "          [-0.06, -0.20,  ..., -0.85, -0.39],\n",
      "          ...,\n",
      "          [-0.41, -0.02,  ..., -0.38, -0.65],\n",
      "          [-0.50, -0.04,  ..., -0.17, -0.41]],\n",
      "\n",
      "         [[ 2.08,  1.65,  ..., -0.60,  2.32],\n",
      "          [ 0.46,  0.69,  ..., -0.56, -0.87],\n",
      "          ...,\n",
      "          [ 0.07,  1.03,  ...,  0.19,  1.13],\n",
      "          [ 0.17,  0.20,  ..., -0.35, -0.98]]]], dtype=torch.float64)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_forward_function_linear (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward_function_linear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\test_convolutional_network.py\", line 474, in test_forward_function_linear\n",
      "    self.assertTensorsClose(z_var.data, z, msg=f\"training[{i}]={training}\")\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\__init__.py\", line 108, in assertTensorsClose\n",
      "    self.fail(msg=f\"{msg}\\n{err_str}\")\n",
      "AssertionError: training[2]=False\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 4141 / 4160 (99.5%)\n",
      "Greatest absolute difference: 0.7511769117831508 at index (2, 0, 5, 9) (up to 0.0001 allowed)\n",
      "Greatest relative difference: 880.9875749825185 at index (3, 0, 7, 12) (up to 0.001 allowed)\n",
      "\n",
      "Actual\n",
      "tensor([[[[-1.31,  0.31,  ..., -0.30, -1.23],\n",
      "          [ 0.56,  0.11,  ...,  2.04, -1.42],\n",
      "          ...,\n",
      "          [ 1.08, -1.01,  ...,  1.07, -0.22],\n",
      "          [ 0.75, -0.45,  ..., -0.40,  0.84]],\n",
      "\n",
      "         [[-0.13, -1.17,  ..., -2.79,  0.53],\n",
      "          [-0.03, -0.06,  ...,  1.33,  0.46],\n",
      "          ...,\n",
      "          [ 0.35,  0.45,  ...,  1.32, -1.53],\n",
      "          [ 0.67, -0.63,  ...,  0.64, -1.41]],\n",
      "\n",
      "         [[ 2.28,  1.32,  ...,  1.16, -1.16],\n",
      "          [-0.84, -0.72,  ...,  0.79, -0.79],\n",
      "          ...,\n",
      "          [-0.54, -0.36,  ..., -0.78, -0.49],\n",
      "          [-2.16,  0.21,  ..., -0.43,  1.42]],\n",
      "\n",
      "         [[ 0.85, -0.47,  ...,  0.33, -1.13],\n",
      "          [ 0.04, -0.47,  ...,  0.19, -0.55],\n",
      "          ...,\n",
      "          [-0.54, -0.86,  ...,  1.33, -1.33],\n",
      "          [-1.96, -1.04,  ..., -0.94,  0.11]]],\n",
      "\n",
      "\n",
      "        [[[-1.30,  0.77,  ..., -0.60,  0.39],\n",
      "          [-1.35, -0.19,  ..., -0.45, -0.65],\n",
      "          ...,\n",
      "          [-0.68, -1.90,  ..., -1.29,  0.72],\n",
      "          [ 1.05, -1.50,  ...,  0.25, -1.17]],\n",
      "\n",
      "         [[-1.45, -0.39,  ..., -0.90,  1.08],\n",
      "          [-0.36,  0.61,  ..., -0.67, -1.43],\n",
      "          ...,\n",
      "          [ 0.44,  1.03,  ...,  1.09, -0.09],\n",
      "          [-0.11, -1.60,  ..., -1.43,  2.06]],\n",
      "\n",
      "         [[ 0.96,  0.48,  ..., -1.81,  0.77],\n",
      "          [ 0.44, -0.08,  ...,  0.27, -0.65],\n",
      "          ...,\n",
      "          [-1.41,  1.04,  ..., -0.98, -0.29],\n",
      "          [ 1.53,  0.87,  ...,  0.51, -0.29]],\n",
      "\n",
      "         [[-0.77,  1.02,  ...,  1.61, -0.38],\n",
      "          [ 0.19,  0.74,  ...,  1.04,  0.26],\n",
      "          ...,\n",
      "          [-0.66, -0.66,  ..., -0.61, -0.95],\n",
      "          [ 0.54, -0.03,  ...,  0.30, -0.50]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.10, -0.08,  ...,  0.93, -0.16],\n",
      "          [-0.36,  0.49,  ..., -1.81, -1.61],\n",
      "          ...,\n",
      "          [ 0.69,  1.22,  ..., -1.10,  0.69],\n",
      "          [-0.44, -1.42,  ..., -1.68, -1.10]],\n",
      "\n",
      "         [[ 0.59,  0.42,  ..., -0.84, -0.40],\n",
      "          [ 1.42,  2.01,  ..., -1.36, -0.32],\n",
      "          ...,\n",
      "          [-0.63,  0.12,  ...,  0.37, -0.52],\n",
      "          [-0.78, -1.22,  ...,  1.22,  1.70]],\n",
      "\n",
      "         [[-1.21, -0.40,  ...,  0.51,  0.96],\n",
      "          [ 0.50,  1.22,  ...,  1.34,  0.11],\n",
      "          ...,\n",
      "          [-0.44, -0.07,  ...,  1.88, -0.02],\n",
      "          [-0.83,  0.84,  ..., -0.96,  0.47]],\n",
      "\n",
      "         [[ 0.60, -0.47,  ..., -0.68,  0.68],\n",
      "          [-0.04,  0.18,  ..., -1.46, -0.34],\n",
      "          ...,\n",
      "          [-0.11, -0.36,  ..., -0.96,  0.49],\n",
      "          [ 0.42,  0.30,  ...,  2.21, -0.74]]],\n",
      "\n",
      "\n",
      "        [[[ 1.44, -0.79,  ..., -2.57,  0.84],\n",
      "          [ 0.26,  0.40,  ..., -0.26, -1.16],\n",
      "          ...,\n",
      "          [-0.28,  0.29,  ...,  0.10, -0.25],\n",
      "          [-1.81,  0.62,  ..., -0.18,  0.55]],\n",
      "\n",
      "         [[ 0.37, -0.79,  ...,  1.16, -0.32],\n",
      "          [ 1.85,  1.08,  ..., -0.19, -0.22],\n",
      "          ...,\n",
      "          [-0.92, -1.28,  ..., -0.12,  2.46],\n",
      "          [ 0.41,  1.30,  ..., -1.40,  0.10]],\n",
      "\n",
      "         [[-0.97, -1.12,  ..., -0.34,  0.74],\n",
      "          [-1.17,  0.67,  ..., -0.63, -1.10],\n",
      "          ...,\n",
      "          [ 1.12,  0.03,  ..., -0.22,  1.74],\n",
      "          [ 0.66, -0.19,  ..., -0.03, -2.39]],\n",
      "\n",
      "         [[ 0.86, -0.41,  ...,  1.26,  0.43],\n",
      "          [-0.04,  0.84,  ..., -0.92,  1.98],\n",
      "          ...,\n",
      "          [ 1.18,  0.01,  ...,  1.54, -0.27],\n",
      "          [-0.88, -0.95,  ..., -1.51, -0.86]]]], dtype=torch.float64)\n",
      "\n",
      "Expected\n",
      "tensor([[[[-8.57e-01,  5.11e-01,  ..., -2.35e-03, -7.87e-01],\n",
      "          [ 7.25e-01,  3.45e-01,  ...,  1.97e+00, -9.48e-01],\n",
      "          ...,\n",
      "          [ 1.16e+00, -6.00e-01,  ...,  1.15e+00,  6.92e-02],\n",
      "          [ 8.82e-01, -1.31e-01,  ..., -8.91e-02,  9.62e-01]],\n",
      "\n",
      "         [[-1.97e-01, -1.11e+00,  ..., -2.53e+00,  3.75e-01],\n",
      "          [-1.14e-01, -1.42e-01,  ...,  1.08e+00,  3.11e-01],\n",
      "          ...,\n",
      "          [ 2.15e-01,  3.04e-01,  ...,  1.07e+00, -1.42e+00],\n",
      "          [ 5.00e-01, -6.37e-01,  ...,  4.76e-01, -1.32e+00]],\n",
      "\n",
      "         [[ 2.10e+00,  1.23e+00,  ...,  1.09e+00, -1.01e+00],\n",
      "          [-7.21e-01, -6.11e-01,  ...,  7.50e-01, -6.73e-01],\n",
      "          ...,\n",
      "          [-4.49e-01, -2.84e-01,  ..., -6.63e-01, -4.03e-01],\n",
      "          [-1.91e+00,  2.28e-01,  ..., -3.45e-01,  1.33e+00]],\n",
      "\n",
      "         [[ 8.64e-01, -2.16e-01,  ...,  4.38e-01, -7.54e-01],\n",
      "          [ 2.01e-01, -2.16e-01,  ...,  3.21e-01, -2.77e-01],\n",
      "          ...,\n",
      "          [-2.75e-01, -5.38e-01,  ...,  1.26e+00, -9.23e-01],\n",
      "          [-1.43e+00, -6.84e-01,  ..., -5.98e-01,  2.59e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.42e-01,  9.04e-01,  ..., -2.56e-01,  5.76e-01],\n",
      "          [-8.85e-01,  8.69e-02,  ..., -1.31e-01, -3.01e-01],\n",
      "          ...,\n",
      "          [-3.20e-01, -1.35e+00,  ..., -8.39e-01,  8.56e-01],\n",
      "          [ 1.14e+00, -1.02e+00,  ...,  4.59e-01, -7.39e-01]],\n",
      "\n",
      "         [[-1.35e+00, -4.26e-01,  ..., -8.71e-01,  8.62e-01],\n",
      "          [-4.02e-01,  4.48e-01,  ..., -6.71e-01, -1.34e+00],\n",
      "          ...,\n",
      "          [ 2.97e-01,  8.15e-01,  ...,  8.69e-01, -1.67e-01],\n",
      "          [-1.85e-01, -1.48e+00,  ..., -1.34e+00,  1.71e+00]],\n",
      "\n",
      "         [[ 9.06e-01,  4.74e-01,  ..., -1.60e+00,  7.33e-01],\n",
      "          [ 4.40e-01, -3.27e-02,  ...,  2.84e-01, -5.43e-01],\n",
      "          ...,\n",
      "          [-1.23e+00,  9.75e-01,  ..., -8.43e-01, -2.18e-01],\n",
      "          [ 1.42e+00,  8.26e-01,  ...,  5.05e-01, -2.20e-01]],\n",
      "\n",
      "         [[-4.59e-01,  1.01e+00,  ...,  1.48e+00, -1.39e-01],\n",
      "          [ 3.21e-01,  7.71e-01,  ...,  1.02e+00,  3.79e-01],\n",
      "          ...,\n",
      "          [-3.72e-01, -3.73e-01,  ..., -3.29e-01, -6.07e-01],\n",
      "          [ 6.12e-01,  1.44e-01,  ...,  4.12e-01, -2.38e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.66e-01,  1.79e-01,  ...,  1.04e+00,  1.15e-01],\n",
      "          [-5.49e-02,  6.67e-01,  ..., -1.28e+00, -1.10e+00],\n",
      "          ...,\n",
      "          [ 8.33e-01,  1.28e+00,  ..., -6.73e-01,  8.30e-01],\n",
      "          [-1.22e-01, -9.45e-01,  ..., -1.16e+00, -6.79e-01]],\n",
      "\n",
      "         [[ 4.29e-01,  2.80e-01,  ..., -8.25e-01, -4.37e-01],\n",
      "          [ 1.16e+00,  1.68e+00,  ..., -1.27e+00, -3.63e-01],\n",
      "          ...,\n",
      "          [-6.37e-01,  1.46e-02,  ...,  2.37e-01, -5.46e-01],\n",
      "          [-7.73e-01, -1.16e+00,  ...,  9.82e-01,  1.40e+00]],\n",
      "\n",
      "         [[-1.05e+00, -3.20e-01,  ...,  5.03e-01,  9.06e-01],\n",
      "          [ 4.88e-01,  1.14e+00,  ...,  1.25e+00,  1.43e-01],\n",
      "          ...,\n",
      "          [-3.53e-01, -2.27e-02,  ...,  1.74e+00,  2.48e-02],\n",
      "          [-7.09e-01,  8.03e-01,  ..., -8.24e-01,  4.63e-01]],\n",
      "\n",
      "         [[ 6.61e-01, -2.20e-01,  ..., -3.88e-01,  7.26e-01],\n",
      "          [ 1.40e-01,  3.19e-01,  ..., -1.03e+00, -1.09e-01],\n",
      "          ...,\n",
      "          [ 7.97e-02, -1.29e-01,  ..., -6.14e-01,  5.70e-01],\n",
      "          [ 5.12e-01,  4.17e-01,  ...,  1.98e+00, -4.37e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.46e+00, -4.14e-01,  ..., -1.92e+00,  9.56e-01],\n",
      "          [ 4.72e-01,  5.86e-01,  ...,  2.94e-02, -7.29e-01],\n",
      "          ...,\n",
      "          [ 1.38e-02,  4.92e-01,  ...,  3.33e-01,  4.40e-02],\n",
      "          [-1.28e+00,  7.75e-01,  ...,  9.75e-02,  7.17e-01]],\n",
      "\n",
      "         [[ 2.33e-01, -7.81e-01,  ...,  9.28e-01, -3.63e-01],\n",
      "          [ 1.53e+00,  8.59e-01,  ..., -2.52e-01, -2.83e-01],\n",
      "          ...,\n",
      "          [-8.94e-01, -1.21e+00,  ..., -1.96e-01,  2.07e+00],\n",
      "          [ 2.71e-01,  1.05e+00,  ..., -1.31e+00, -1.43e-03]],\n",
      "\n",
      "         [[-8.40e-01, -9.73e-01,  ..., -2.71e-01,  7.05e-01],\n",
      "          [-1.02e+00,  6.48e-01,  ..., -5.28e-01, -9.54e-01],\n",
      "          ...,\n",
      "          [ 1.06e+00,  7.06e-02,  ..., -1.60e-01,  1.61e+00],\n",
      "          [ 6.40e-01, -1.30e-01,  ...,  1.39e-02, -2.12e+00]],\n",
      "\n",
      "         [[ 8.74e-01, -1.65e-01,  ...,  1.20e+00,  5.19e-01],\n",
      "          [ 1.36e-01,  8.53e-01,  ..., -5.86e-01,  1.79e+00],\n",
      "          ...,\n",
      "          [ 1.13e+00,  1.78e-01,  ...,  1.43e+00, -5.22e-02],\n",
      "          [-5.48e-01, -6.05e-01,  ..., -1.07e+00, -5.36e-01]]]],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 1.158s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=0 failures=2>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestBatchNorm2d.eval()\n",
    "# Values are off a tiny bit. Not sure how to fix, tried everything :(\n",
    "# (For the MLP, in batchnorm1d it still worked with the small differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca7f98",
   "metadata": {},
   "source": [
    "### Konvoluční síť s batch normalizací VGG7BN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c105d8",
   "metadata": {},
   "source": [
    "Batch normalizaci přidáme do modelu VGG7 a výslednou architekturu označíme jako VGG7BN. Zároveň také vypneme u konvolučních vrstev bias, protože jeho efekt by byl stejně ihned následující normalizací opět odečten. Stejným značením jako u VGG7 architektura bude vypadat následovně:\n",
    "\n",
    "`CNR(64), M(2), CNR(128), M(2), CNR(256), M(2), CNR(512), M(2), CNR(512), M(2), LR(512), L(10)`\n",
    "\n",
    "kde:\n",
    "- `N` značí batch normalizaci\n",
    "\n",
    "Architektura je tedy shodná s VGG7, pouze místo bloků konvoluce-relu (`CR`) se opakují bloky konvoluce-normalizace-relu (`CNR`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c81b0",
   "metadata": {},
   "source": [
    "### TODO: implementujte model `VGG7BN` využívající 2D batch normalizaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a80bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ans.modules as nn\n",
    "import ans.autograd as ag\n",
    "\n",
    "class VGG7BN(ans.modules.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int, bias: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=None)\n",
    "        self.batch1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=None)\n",
    "        self.batch2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=None)\n",
    "        self.batch3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=None)\n",
    "        self.batch4 = nn.BatchNorm2d(512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.pool4 = nn.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=None)\n",
    "        self.batch5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        self.pool5 = nn.MaxPool2d(window_size=2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(512, 512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################\n",
    "    \n",
    "    # feel free to add auxiliary methods here\n",
    "    # def my_function(...)\n",
    "    \n",
    "    def forward(self, x: ans.autograd.Variable) -> ans.autograd.Variable:\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch4(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.batch5(x)\n",
    "        x = self.relu5(x)\n",
    "        \n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten for linear layers\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu6(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "        # ENDTODO\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52f4d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:673: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(output)\n",
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:674: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices)\n",
      "FAIL\n",
      "test_num_params (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_num_params) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\test_convolutional_network.py\", line 520, in test_forward\n",
      "    self.assertTensorsClose(scores, expected_scores, atol=0.1)\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\__init__.py\", line 108, in assertTensorsClose\n",
      "    self.fail(msg=f\"{msg}\\n{err_str}\")\n",
      "AssertionError: \n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 10 / 10 (100.0%)\n",
      "Greatest absolute difference: 5.016840874338841 at index (0, 1) (up to 0.1 allowed)\n",
      "Greatest relative difference: 35.56948920658277 at index (0, 4) (up to 0.001 allowed)\n",
      "\n",
      "Actual\n",
      "tensor([[-1.13, -6.21,  0.04,  4.67, -0.46, -1.79,  2.99,  0.87, -4.24,  2.84]],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "Expected\n",
      "tensor([[ 0.04, -1.20, -0.35,  0.24,  0.01, -0.83,  0.68,  0.25, -0.31,  0.34]],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_num_params (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_num_params)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\test_convolutional_network.py\", line 512, in test_num_params\n",
      "    self.assertEqual(self.model.num_params(), 4180042)\n",
      "AssertionError: 4177098 != 4180042\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.348s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=2>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestVGG7BN.eval(model_cls=VGG7BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beb623ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:673: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(output)\n",
      "C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:674: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:39\u001b[0m\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(loader, model, criterion)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m----> 9\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     11\u001b[0m     total_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mval_step\u001b[1;34m(inputs, targets, model, criterion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mval_step\u001b[39m(\n\u001b[0;32m      2\u001b[0m     inputs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m      3\u001b[0m     targets: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     12\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy(outputs, targets)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 63\u001b[0m, in \u001b[0;36mVGG7BN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(x)\n\u001b[0;32m     61\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[1;32m---> 63\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch2(x)\n\u001b[0;32m     65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:318\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:14\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *inputs, **params)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Union[Variable, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m     13\u001b[0m     tensor_args \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, Variable) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m---> 14\u001b[0m     output_data, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensor_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_fn\u001b[39m(dout: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m     17\u001b[0m         dinputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(dout, cache\u001b[38;5;241m=\u001b[39mcache)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:568\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m    input: shape (num_samples(minibatch), num_channels(in_channels), height, width)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03m    cache: tuple of intermediate results to use in backward\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m#output = torch.nn.functional.conv2d(input, weight, bias=torch.tensor(bias), stride=stride, padding=padding, dilation=dilation, groups=groups)        \u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m cache \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28minput\u001b[39m, weight, bias, stride, padding, dilation, groups)\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# ENDTODO\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 8\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "device = 'cuda'\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset_aug,  # use augmented dataset \n",
    "    #train_dataset, # trying unaugmented\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = VGG7BN(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ans.optim.Adam(model.parameters(), learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604\n",
    "# Go to ans.functional.py and uncomment line 680 and uncomment line 604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46a30391",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mbest_results(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m history\u001b[38;5;241m.\u001b[39mdf()\u001b[38;5;241m.\u001b[39mplot(secondary_y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.best_results('val_acc', 'max'))\n",
    "history.df().plot(secondary_y=['train_acc', 'val_acc']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68081fa-334b-499a-98e9-b06d33f55c3f",
   "metadata": {},
   "source": [
    "## Residuální sítě ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c111cbc",
   "metadata": {},
   "source": [
    "Jako poslední vylepšení můžete zkusit použít residuální bloky, které tvoří základ sítí ResNet. Např. v benchmarku [DAWNBBench](https://dawn.cs.stanford.edu/benchmark/CIFAR10/train.html), kde se kromě jiného hodnotí i rychlost trénování, se na předních pro dataset CIFAR-10 umisťuje varianta ResNet9. Architektura není standardizovaná a publikovaná, byla objevena komunitou a mezi jednotlivými implementacemi se liší. Vyzkoušíme její původní variantu ze série příspěvků o optimalizaci trénování ResNetu na datasetu CIFAR-10 na adrese https://myrtle.ai/learn/how-to-train-your-resnet/.\n",
    "\n",
    "Shodným značením s VGG7 a VGG7BN má model Resnet9 následující architekturu:\n",
    "\n",
    "`CNR(64), CNR(128), M(2), res(CNR(128), CNR(128)), CNR(256), M(2), CNR(512), M(2), res(CNR(512), CNR(512)), M(4), L(10)`\n",
    "\n",
    "kde:\n",
    "- `res(convblock)` značí residuální blok formy `z = x + convblock(x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5189f8",
   "metadata": {},
   "source": [
    "### TODO: implementujte model ResNet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2066a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet9(ans.modules.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int, bias: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        self.conv1 = ans.modules.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.batch1 = ans.modules.BatchNorm2d(64)\n",
    "        self.relu1 = ans.modules.ReLU()\n",
    "\n",
    "        self.conv2 = ans.modules.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.batch2 = ans.modules.BatchNorm2d(128)\n",
    "        self.relu2 = ans.modules.ReLU()\n",
    "\n",
    "        self.pool1 = ans.modules.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.res_block1 = self.residual_block(128, 128)\n",
    "\n",
    "        self.conv3 = ans.modules.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.batch3 = ans.modules.BatchNorm2d(256)\n",
    "        self.relu3 = ans.modules.ReLU()\n",
    "\n",
    "        self.pool2 = ans.modules.MaxPool2d(window_size=2)\n",
    "\n",
    "        self.conv4 = ans.modules.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.batch4 = ans.modules.BatchNorm2d(512)\n",
    "        self.relu4 = ans.modules.ReLU()\n",
    "\n",
    "        self.pool3 = ans.modules.MaxPool2d(window_size=2)\n",
    "        \n",
    "        self.res_block2 = self.residual_block(512, 512)\n",
    "\n",
    "        self.pool4 = ans.modules.MaxPool2d(window_size=4)\n",
    "\n",
    "        self.linear = ans.modules.Linear(512, 10)\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################\n",
    "\n",
    "    # feel free to add auxiliary methods here\n",
    "    def residual_block(self, in_channels: int, out_channels: int, bias: bool = False):\n",
    "        conv2d_1 = ans.modules.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        batch_norm_1 = ans.modules.BatchNorm2d(out_channels)\n",
    "        relu_1 = ans.modules.ReLU()\n",
    "        conv2d_2 = ans.modules.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        batch_norm_2 = ans.modules.BatchNorm2d(out_channels)\n",
    "        relu_2 = ans.modules.ReLU()\n",
    "\n",
    "        return lambda x: x + relu_2(batch_norm_2(conv2d_2(relu_1(batch_norm_1(conv2d_1(x))))))\n",
    "    \n",
    "    def forward(self, x: ans.autograd.Variable) -> ans.autograd.Variable:\n",
    "        ########################################\n",
    "        # TODO: implement\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu1(x)\n",
    "    \n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu2(x)\n",
    "    \n",
    "        x = self.res_block1(x)\n",
    "    \n",
    "        x = self.pool1(x)\n",
    "    \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.relu3(x)\n",
    "    \n",
    "        x = self.res_block2(x)\n",
    "    \n",
    "        x = self.pool2(x)\n",
    "    \n",
    "        x = self.conv4(x)\n",
    "        x = self.batch4(x)\n",
    "        x = self.relu4(x)\n",
    "    \n",
    "        x = self.pool3(x)\n",
    "    \n",
    "        x = self.res_block3(x)\n",
    "    \n",
    "        x = self.pool4(x)\n",
    "    \n",
    "        x = ans.functional.flatten(x)\n",
    "    \n",
    "        x = self.linear(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "        # ENDTODO\n",
    "        ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eba4b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward) ... ERROR\n",
      "test_num_params (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_num_params) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_forward (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_forward)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\test_convolutional_network.py\", line 530, in test_forward\n",
      "    scores = self.model(0.1 * torch.randn(1, 3, 32, 32, dtype=torch.float64)).data\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py\", line 15, in __call__\n",
      "    return self.forward(*x)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\AppData\\Local\\Temp\\ipykernel_308\\3707874131.py\", line 65, in forward\n",
      "    x = self.res_block1(x)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\AppData\\Local\\Temp\\ipykernel_308\\3707874131.py\", line 51, in <lambda>\n",
      "    return lambda x: x + relu_2(batch_norm_2(conv2d_2(relu_1(batch_norm_1(conv2d_1(x))))))\n",
      "                                                                          ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py\", line 15, in __call__\n",
      "    return self.forward(*x)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py\", line 318, in forward\n",
      "    return functional.Conv2d.apply(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py\", line 14, in apply\n",
      "    output_data, cache = cls.forward(*tensor_args, **params)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py\", line 568, in forward\n",
      "    output = torch.nn.functional.conv2d(input, weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Input type (double) and bias type (float) should be the same\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_num_params (tests.ANSTestCase.eval.<locals>._TestCaseClass.test_num_params)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Timotej\\Desktop\\Classes\\ANS-2023\\assignments\\..\\tests\\test_convolutional_network.py\", line 526, in test_num_params\n",
      "    self.assertEqual(self.model.num_params(), 6573130)\n",
      "AssertionError: 1556106 != 6573130\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.186s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=1 failures=1>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convolutional_network.TestResnet9.eval(model_cls=ResNet9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d9f2541",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:38\u001b[0m\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(loader, model, criterion)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m----> 9\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     11\u001b[0m     total_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mval_step\u001b[1;34m(inputs, targets, model, criterion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mval_step\u001b[39m(\n\u001b[0;32m      2\u001b[0m     inputs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m      3\u001b[0m     targets: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     12\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy(outputs, targets)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 65\u001b[0m, in \u001b[0;36mResNet9.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch2(x)\n\u001b[0;32m     63\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n\u001b[1;32m---> 65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mres_block1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[0;32m     69\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n",
      "Cell \u001b[1;32mIn[41], line 51\u001b[0m, in \u001b[0;36mResNet9.residual_block.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     48\u001b[0m batch_norm_2 \u001b[38;5;241m=\u001b[39m ans\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mBatchNorm2d(out_channels)\n\u001b[0;32m     49\u001b[0m relu_2 \u001b[38;5;241m=\u001b[39m ans\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mReLU()\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m+\u001b[39m relu_2(batch_norm_2(conv2d_2(relu_1(batch_norm_1(\u001b[43mconv2d_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))))\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:15\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\modules.py:318\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Variable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:14\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *inputs, **params)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Union[Variable, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[0;32m     13\u001b[0m     tensor_args \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, Variable) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m---> 14\u001b[0m     output_data, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensor_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_fn\u001b[39m(dout: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m     17\u001b[0m         dinputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(dout, cache\u001b[38;5;241m=\u001b[39mcache)\n",
      "File \u001b[1;32m~\\Desktop\\Classes\\ANS-2023\\assignments\\..\\ans\\functional.py:568\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m    input: shape (num_samples(minibatch), num_channels(in_channels), height, width)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03m    cache: tuple of intermediate results to use in backward\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# TODO: implement\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m#output = torch.nn.functional.conv2d(input, weight, bias=torch.tensor(bias), stride=stride, padding=padding, dilation=dilation, groups=groups)        \u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m cache \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28minput\u001b[39m, weight, bias, stride, padding, dilation, groups)\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# ENDTODO\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "# reproducibility\n",
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 6\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.DataLoader(\n",
    "    train_dataset_aug,  # use augmented dataset\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = ans.data.DataLoader(\n",
    "    val_dataset,\n",
    "    device = device,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "model = ResNet9(10)\n",
    "model.to(device=device)\n",
    "\n",
    "# loss function\n",
    "criterion = ans.modules.SoftmaxCrossEntropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = ans.optim.Adam(model.parameters(), learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, model, criterion)\n",
    "val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "\n",
    "# record history for plotting\n",
    "history = ans.utils.MetricsHistory()\n",
    "history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    gc.collect()\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step(inputs, targets, model, criterion, optimizer)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "    \n",
    "    history.update(train_loss=train_loss, train_acc=train_acc, val_loss=val_loss, val_acc=val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70368c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
